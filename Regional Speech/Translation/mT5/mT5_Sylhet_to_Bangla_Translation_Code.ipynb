{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H8qkhqIo0FMM"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "vxoNB55w0Rov",
    "outputId": "ebf9a00b-9532-472a-f733-2985fb4ed615"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N26NczH_0Rru"
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"/content/Sylhet_Translation_Main_Train_Dataset.csv\")\n",
    "test_data = pd.read_csv(\"/content/Sylhet_Translation_Main_Test_Dataset.csv\")\n",
    "validation_data = pd.read_csv(\"/content/Sylhet_Translation_Main_Validation_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "lPw8DnT11xk1",
    "outputId": "835501f9-5807-45a8-fd05-326b33057863"
   },
   "outputs": [],
   "source": [
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ZeMgko9S2W-H",
    "outputId": "e57ddf08-a2ee-43f0-8c74-647d772e1cc3"
   },
   "outputs": [],
   "source": [
    "# Rename the columns to match the expected format\n",
    "train_data.rename(columns={'sylhet_bangla_speech': 'input_text', 'bangla_speech': 'labels'}, inplace=True)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "HUAW0qqt1x_V",
    "outputId": "e523fe8c-a2bb-402d-dcfa-ce2d98a95dca"
   },
   "outputs": [],
   "source": [
    "test_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ICeu3MvG2Xkn",
    "outputId": "f29cb21d-d394-4fc8-e14a-173ececc273d"
   },
   "outputs": [],
   "source": [
    "# Rename the columns to match the expected format\n",
    "test_data.rename(columns={'sylhet_bangla_speech': 'input_text', 'bangla_speech'\t: 'labels'}, inplace=True)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "EbjGz7KX11vG",
    "outputId": "0fc78d83-c27d-451e-e047-00750994891d"
   },
   "outputs": [],
   "source": [
    "validation_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "vxr9N4Oz2ZUL",
    "outputId": "2f65f47e-2b04-4d17-b34c-7cced66dd48e"
   },
   "outputs": [],
   "source": [
    "# Rename the columns to match the expected format\n",
    "validation_data.rename(columns={'sylhet_bangla_speech': 'input_text', 'bangla_speech'\t: 'labels'}, inplace=True)\n",
    "validation_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "LvZU0YCz5S6T",
    "outputId": "40746c47-d6a3-492e-ac3b-106ec538f3c7"
   },
   "outputs": [],
   "source": [
    "!pip install transformers torch pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "ewgAuAdN5lOD",
    "outputId": "a96adb8f-9294-4411-adbc-f09604fa74e4"
   },
   "outputs": [],
   "source": [
    "!pip install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "mSWbj-Qx5lRB",
    "outputId": "cd727367-5f98-47f1-8813-154ee5f59419"
   },
   "outputs": [],
   "source": [
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "gksX0-7G5lWi",
    "outputId": "129f32bb-1c08-4426-f774-056432547094"
   },
   "outputs": [],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "nikoCtvm5lZ7",
    "outputId": "befa32df-a9bb-4761-8f51-095178e09bea"
   },
   "outputs": [],
   "source": [
    "!pip install transformers[sentencepiece]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "A7tBHm2v5th9",
    "outputId": "b2ebbc0c-7b6e-46d3-a94e-aeaf59721ec7"
   },
   "outputs": [],
   "source": [
    "!transformers-cli cache clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "7ir8YLuX5t3k",
    "outputId": "c14c7521-1d02-49ee-da7c-b1d850bbed0c"
   },
   "outputs": [],
   "source": [
    "!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "4-2iB14y6DJv",
    "outputId": "0503d467-9d4a-4645-b9ab-dec29d68957f"
   },
   "outputs": [],
   "source": [
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "4_Be4m5g6Ewv",
    "outputId": "8532bef0-b480-4a5d-ea46-e314981ea80f"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/csebuetnlp/normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "Ft7z0inq6GR4",
    "outputId": "21be8a71-6219-4810-b634-81991fee22b1"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "3WqqErcR6GoA",
    "outputId": "1e65a233-b40d-404f-8c36-ded434cd492d"
   },
   "outputs": [],
   "source": [
    "!pip install transformers==4.10.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "ysKhQyvN6I_o",
    "outputId": "64295efd-af29-4993-d1e8-36090fdd85bb"
   },
   "outputs": [],
   "source": [
    "!pip install torch transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "G4_9m3MP6K_R",
    "outputId": "7f5168fc-024f-4716-d356-d81668901c57"
   },
   "outputs": [],
   "source": [
    "!pip install accelerate==0.20.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "IyFWplMAtNq_",
    "outputId": "b2e999a0-d2b8-4dbf-83d9-2a3be3e9f8a9"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/csebuetnlp/normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6JtTux4mnn6Q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r7wCqcXJnPB-"
   },
   "source": [
    "# **Load the model and tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "n0ehjo-qnous",
    "outputId": "dff5931f-17b0-48bc-b337-f0370f04da7c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yY2lps5K49Ei"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from normalizer import normalize\n",
    "from transformers import MT5ForConditionalGeneration, AutoTokenizer ,DataCollatorForSeq2Seq, Trainer, TrainingArguments\n",
    "import os\n",
    "\n",
    "# Load the saved model\n",
    "model = MT5ForConditionalGeneration.from_pretrained(\"/content/drive/MyDrive/movie/sylhet_translation_mT5.pt\")\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/movie/sylhet_tokenizer_mT5.json\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4fxLl_2k27zr"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class Seq2SeqDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length=128):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data: A DataFrame containing 'input_text' and 'labels' columns.\n",
    "            tokenizer: A Hugging Face tokenizer.\n",
    "            max_length: Maximum sequence length.\n",
    "        \"\"\"\n",
    "        self.input_text = data['input_text'].apply(normalize).tolist()\n",
    "        self.labels = data['labels'].apply(normalize).tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_text)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_text = self.input_text[idx]\n",
    "        label_text = self.labels[idx]\n",
    "\n",
    "        # Tokenize the input text\n",
    "        input_encodings = self.tokenizer(\n",
    "            input_text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        # Tokenize the label text to get its 'input_ids' and 'attention_mask'\n",
    "        label_encodings = self.tokenizer(\n",
    "            label_text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_encodings['input_ids'].squeeze(),\n",
    "            'attention_mask': input_encodings['attention_mask'].squeeze(),\n",
    "            'labels': label_encodings['input_ids'].squeeze(),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zpdutUxB2727"
   },
   "outputs": [],
   "source": [
    "# Create train , test and validation datasets\n",
    "train_dataset = Seq2SeqDataset(train_data, tokenizer)\n",
    "test_dataset = Seq2SeqDataset(test_data, tokenizer)\n",
    "validation_dataset = Seq2SeqDataset(validation_data, tokenizer)\n",
    "\n",
    "# Create train , test and validation dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)  #batch_size=32\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16) #batch_size=32\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=16) #batch_size=32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "qVyxO66e3F9Q",
    "outputId": "87a965c6-4ba6-4f73-da34-57d7ec05eaf9"
   },
   "outputs": [],
   "source": [
    "# Move the model to the device (CPU or GPU)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UIYgPkGm9jli"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AdamW\n",
    "from torch.optim import AdamW\n",
    "\n",
    "# Create a custom optimizer using torch.optim.AdamW\n",
    "custom_optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=1e-3,  # Learning rate\n",
    "    eps=1e-8,  # Epsilon value to prevent division by zero\n",
    "    weight_decay=0.01,  # Weight decay (L2 regularization)\n",
    ")\n",
    "\n",
    "# Define the TrainingArguments for fine-tuning\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='/content/drive/MyDrive/movie/sylhet_translation_mT5/model_fine_tuned',\n",
    "    num_train_epochs=50,  # You can adjust the number of epochs\n",
    "    per_device_train_batch_size=6,  # You can adjust the batch size\n",
    "    gradient_accumulation_steps=8,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    save_total_limit=2,\n",
    "    save_steps=1000,\n",
    "    learning_rate=1e-3,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    remove_unused_columns=False,\n",
    "    push_to_hub=False,\n",
    "    report_to=\"none\",\n",
    "    load_best_model_at_end=True,\n",
    "    lr_scheduler_type=\"cosine_with_restarts\",\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='/content/drive/MyDrive/movie/sylhet_translation_mT5/model_fine_tuned',\n",
    "    logging_steps=50,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RtJSY_gF3Zs5"
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "# Create a data collator for sequence-to-sequence tasks\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,  # Your Hugging Face tokenizer\n",
    "    model=model,\n",
    "    padding=True,\n",
    "    max_length=128,\n",
    "    label_pad_token_id=tokenizer.pad_token_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qHBr8I2f1Ekc"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,  # Use the model you loaded\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,  # Use your data collator\n",
    "    train_dataset=train_dataset,  # Use your training dataset\n",
    "    eval_dataset=validation_dataset,  # Use your evaluation dataset\n",
    "    optimizers=(custom_optimizer, None),  # Use your custom optimizer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1440
    },
    "id": "AzroKJHm-50G",
    "outputId": "0422f2a3-8060-4f54-a89e-3df2cde1dca9"
   },
   "outputs": [],
   "source": [
    "# Fine-tune the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4qQMPeD3lifb"
   },
   "source": [
    "# **Save the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "eIsLiye31J-1",
    "outputId": "a006c520-c234-4ae4-f0ab-0484a4009fa7"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "# Save the model\n",
    "model.save_pretrained(\"/content/drive/MyDrive/movie/sylhet_translation_mT5.pt\")\n",
    "\n",
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained(\"/content/drive/MyDrive/movie/sylhet_tokenizer_mT5.json\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WtQNx_UWllTr"
   },
   "source": [
    "# **Load the model again**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dhJTzFGf31jO"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "# Load the saved model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"/content/drive/MyDrive/movie/sylhet_translation_mT5.pt\")\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/movie/sylhet_tokenizer_mT5.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "Y4931GPs35p2",
    "outputId": "f94129eb-33fc-4023-944b-44fd53ae7c00"
   },
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "0LySOpK-4Ej6",
    "outputId": "3ff53b51-ed07-478b-958d-fa4669ca56d6"
   },
   "outputs": [],
   "source": [
    "!pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "D-cSDMgC4Eoh",
    "outputId": "21f10431-add8-4f78-811a-002c6557f445"
   },
   "outputs": [],
   "source": [
    "!pip install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "WJS-YMDM4Erp",
    "outputId": "54697706-0741-474b-80d0-42490514d450"
   },
   "outputs": [],
   "source": [
    "# Move the model to the device (CPU or GPU)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "XtdovWlt4JKz",
    "outputId": "0d1bb779-881e-47d3-8f9c-d8757263439c"
   },
   "outputs": [],
   "source": [
    "!pip install rouge-score\n",
    "#https://github.com/google-research/google-research/tree/master/rouge\n",
    "#https://huggingface.co/spaces/evaluate-metric/rouge [Different types of ROUGE scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "nwOqAGUB4JNr",
    "outputId": "2126c952-a4a5-48a2-a64a-caadf141d92b"
   },
   "outputs": [],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "eEpSQZQi4JRE",
    "outputId": "682f8efe-9f20-4bd7-c390-ea615ae742c2"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import Levenshtein\n",
    "from evaluate import load\n",
    "# Define the move_to_device function\n",
    "def move_to_device(batch, device):\n",
    "    if isinstance(batch, torch.Tensor):\n",
    "        return batch.to(device)\n",
    "    elif isinstance(batch, list):\n",
    "        return [move_to_device(item, device) for item in batch]\n",
    "    elif isinstance(batch, dict):\n",
    "        return {key: move_to_device(value, device) for key, value in batch.items()}\n",
    "    else:\n",
    "        return batch  # If it's not a tensor, list, or dict, leave it as is\n",
    "\n",
    "# Load the evaluation metric for Character Error Rate (CER) and Word Error Rate (WER) and Exact Match(em)\n",
    "cer_metric = load(\"cer\")\n",
    "wer_metric = load(\"wer\")\n",
    "meteor = load('meteor')\n",
    "exact_match_metric = load(\"exact_match\")\n",
    "\n",
    "# Load BLEU and ROUGE metrics\n",
    "bleu_metric = load(\"bleu\")\n",
    "rouge_metric = load('rouge')\n",
    "\n",
    "# Initialize lists to store generated translations and references\n",
    "generated_translations = []\n",
    "references = []\n",
    "\n",
    "# Generate translations for the test dataset\n",
    "for batch in test_dataloader:\n",
    "    # Move the batch to CUDA\n",
    "    batch = move_to_device(batch, 'cuda')\n",
    "\n",
    "    input_text = batch['input_ids']  # Access the input_text using the correct key\n",
    "    labels = batch['labels']  # Access the labels using the correct key\n",
    "\n",
    "    # Generate translations\n",
    "    translation_ids = model.generate(input_text, max_length=128, num_beams=4, length_penalty=2.0, early_stopping=True)\n",
    "\n",
    "    # Move the translation_ids to CPU to decode\n",
    "    translation_ids = translation_ids.to('cpu')\n",
    "\n",
    "    generated_translation = tokenizer.batch_decode(translation_ids, skip_special_tokens=True)\n",
    "\n",
    "    generated_translations.extend(generated_translation)\n",
    "    references.extend(tokenizer.batch_decode(labels, skip_special_tokens=True))  # Decoding the label IDs\n",
    "\n",
    "# Make sure to move generated_translations back to CPU for evaluation if necessary\n",
    "generated_translations = [translation if not isinstance(translation, str) else translation for translation in generated_translations]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "cg69Lnfm4PyI",
    "outputId": "4d04cb8c-2549-4d61-a965-9c3d66c31355"
   },
   "outputs": [],
   "source": [
    "print(\"Number of generated translations:\", len(generated_translations))\n",
    "print(\"Number of references:\", len(references))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "h_AS7K9P4P1G",
    "outputId": "d17665ea-c9b9-4883-9ac9-1deff4050b12"
   },
   "outputs": [],
   "source": [
    "print(generated_translations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "n8Y7DH9r4P3-",
    "outputId": "5acd8329-ccc1-476d-e4bd-3f50c46f0a80"
   },
   "outputs": [],
   "source": [
    "print(references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6TLPIr5Z4Uc4"
   },
   "outputs": [],
   "source": [
    "# Calculate Character Error Rate (CER) and Word Error Rate (WER)\n",
    "results_CER = cer_metric.compute(predictions=generated_translations, references=references)\n",
    "results_WER = wer_metric.compute(predictions=generated_translations, references=references)\n",
    "\n",
    "# Calculate Exact Match (EM) and METEOR(M)\n",
    "results_em = exact_match_metric.compute(predictions=generated_translations, references=references)\n",
    "results_met = meteor.compute(predictions=generated_translations, references=references)\n",
    "\n",
    "# Calculate Bilingual Evaluation Understudy (BLEU) and Recall-Oriented Understudy for Gisting Evaluation (ROUGE)\n",
    "results_bleu = bleu_metric.compute(predictions=generated_translations, references=references)\n",
    "results_rouge = rouge_metric.compute(predictions=generated_translations, references=references)\n",
    "\n",
    "\n",
    "# Calculate Levenshtein Distance\n",
    "levenshtein_distances = [Levenshtein.distance(generated, reference) for generated, reference in zip(generated_translations, references)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "g1j43gyg4Ufx",
    "outputId": "87770141-e6df-4696-dccc-be2e2b7f194f"
   },
   "outputs": [],
   "source": [
    "print(results_CER)\n",
    "print(results_WER)\n",
    "print(results_em)\n",
    "print(results_met)\n",
    "print(results_bleu)\n",
    "print(results_rouge)\n",
    "print(levenshtein_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "TAW7J9vB4Uio",
    "outputId": "b4f4f754-817f-4c19-bf13-a72ce0788282"
   },
   "outputs": [],
   "source": [
    "total_correct = 0\n",
    "total_samples = len(references)\n",
    "\n",
    "for generated, reference in zip(generated_translations, references):\n",
    "    levenshtein_distance = Levenshtein.distance(generated, reference)\n",
    "    max_length = max(len(generated), len(reference))\n",
    "    accuracy = 1 - (levenshtein_distance / max_length)\n",
    "    if accuracy >= 0.8:  # Adjust the threshold as needed\n",
    "        total_correct += 1\n",
    "\n",
    "accuracy = total_correct / total_samples\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_Ltrb2plro-"
   },
   "source": [
    "# **Save translation results to a csv file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v6lkFghx4Yb0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame to store translations\n",
    "translation_df = pd.DataFrame({\n",
    "    'input_text': test_data['input_text'],  # Assuming 'test_data' contains your test dataset\n",
    "    'labels': references,\n",
    "    'translations': generated_translations\n",
    "})\n",
    "\n",
    "# Save translations to a CSV file\n",
    "#translation_df.to_csv(\"/content/drive/MyDrive/sylhet_translation_results/sylhet_translation_mT5/model_fine_tuned/mBERT_sylhet_translation.csv\", index=False)\n",
    "# Save translations to a CSV file\n",
    "translation_df.to_excel('/content/sample_data/sylhet_translations_mT5.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7wfJgttirFfT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
